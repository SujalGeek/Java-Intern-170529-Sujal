## =========================================================
## Basic Application Info
## =========================================================
#spring.application.name=Spring-AI-Ollama
#server.port=8080
#
## =========================================================
##  Ollama Configuration
## =========================================================
#spring.ai.ollama.base-url=http://localhost:11434
#spring.ai.ollama.chat.options.model=tinyllama
#spring.ai.ollama.chat.options.num_predict=128
#spring.ai.ollama.embedding.model=nomic-embed-text
#spring.ai.ollama.chat.options.temperature=0.7
#
## =========================================================
##  MariaDB Database Configuration
## =========================================================
#spring.datasource.url=jdbc:mariadb://localhost:3308/springai2
#spring.datasource.username=root
#spring.datasource.password=root
#spring.datasource.driver-class-name=org.mariadb.jdbc.Driver
#
## =========================================================
## Vector Store Configuration for MariaDB
## =========================================================
## Since you are storing embeddings as BLOB (not VECTOR),
## we must disable schema validation and avoid vector-type assumptions.
#spring.ai.vectorstore.mariadb.initialize-schema=true
#spring.ai.vectorstore.mariadb.use-vector-data-type=false
#spring.ai.vectorstore.mariadb.vector-table-validations-enabled=false
#
## Optional: if you want Spring AI to auto-create the table when missing,
## you can set the following to true (but you already created it manually):
## spring.ai.vectorstore.mariadb.initialize-schema=true
##spring.ai.vectorstore.mariadb.enabled=false
#
## Keep the same distance type and dimension
#spring.ai.vectorstore.mariadb.distance-type=COSINE
#spring.ai.vectorstore.mariadb.dimensions=768
#
## =========================================================
## Chat Memory (Optional - for conversation context)
## =========================================================
## If you?re NOT using chat memory, disable this to prevent schema errors.
spring.ai.chat.memory.jdbc.enabled=false
## or if you use it:
## spring.ai.chat.memory.repository.jdbc.initialize-schema=ALWAYS
#
## =========================================================
## Logging (Optional - for debugging)
## =========================================================
#logging.level.org.springframework.ai.chat.client.advisor=DEBUG
#logging.level.org.springframework.ai.vectorstore.mariadb=INFO




advisor.token.enabled=false

# =========================================================
# Basic Application Info
# =========================================================
spring.application.name=Spring-AI-Ollama
server.port=8080

# =========================================================
#  Ollama Configuration
# =========================================================
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=tinyllama
spring.ai.ollama.embedding.model=nomic-embed-text
spring.ai.ollama.chat.options.temperature=0.7

# =========================================================
#  PostgreSQL (pgvector) Database Configuration
# =========================================================
# This connects to the 'ankane/pgvector' Docker container
spring.datasource.url=jdbc:postgresql://localhost:5432/mydb
spring.datasource.username=myuser
spring.datasource.password=mysecretpassword
spring.datasource.driver-class-name=org.postgresql.Driver

# =========================================================
# Vector Store Configuration for pgvector
# =========================================================
# Automatically create the 'vector_store' table
spring.ai.vectorstore.pgvector.initialize-schema=true
# Dimensions must match your embedding model (nomic-embed-text)
spring.ai.vectorstore.pgvector.dimensions=768
spring.ai.chat.memory.enabled=false
